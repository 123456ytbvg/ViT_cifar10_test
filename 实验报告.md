# 实验三：CIFAR-ViT 图像分类实验报告

## 1. 实验背景

### 1.1 实验目的
本实验旨在深入理解 Vision Transformer (ViT) 的结构与工作原理，掌握自注意力机制在图像分类任务中的应用。通过在 CIFAR-10 数据集上实现 ViT，并在不均衡数据和模型轻量化两方面进行改进，培养模型优化与分析能力。

### 1.2 理论基础
- **自注意力机制（Self-Attention）**：通过计算图像块间的相关性实现全局特征建模，克服 CNN 的局部感受野限制。  
- **Vision Transformer (ViT)**：将图像分割为固定大小的 patch，经线性嵌入后输入 Transformer 编码器，完成特征提取与分类。  
- **轻量化思想**：通过结构剪枝、动态计算或量化等方式减少计算量与参数规模，提高推理效率。

---

## 2. 实验内容与要求

### 2.1 实验任务说明
利用 PyTorch 框架搭建 ViT 模型，在 CIFAR-10 数据集上完成分类任务，并在保证性能的前提下解决以下两类问题：
1. **类不均衡问题**：训练集为 `CIFAR10_imbalanced`，测试集为 `CIFAR10_balance`；
2. **模型轻量化问题**：通过至少两种轻量化方法减少模型计算量与参数量。

### 2.2 数据集说明

```bash
成功加载训练集，总样本数: 35580
成功加载测试集，总样本数: 4870
  类别: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
训练集类别分布:
  类别 0: 4435 个样本
  类别 1: 4189 个样本
  类别 2: 3065 个样本
  类别 3: 4191 个样本
  类别 4: 4513 个样本
  类别 5: 3717 个样本
  类别 6: 3513 个样本
  类别 7: 3249 个样本
  类别 8: 2685 个样本
  类别 9: 2023 个样本
  类别: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
训练样本: 32,022
验证样本: 3,558
测试样本: 4,870
```

- **CIFAR-10 简介**：包含 10 个类别，共 60,000 张 32×32 彩色图像。 
- **训练集与测试集划分**：  
  - 训练集：CIFAR10_imbalanced（各类样本数不均衡）  
  - 测试集：CIFAR10_balance（类别平衡）  
- **问题特征**：类别不均衡导致模型倾向于预测多数类，影响泛化性能。

### 2.3 实验要求
- 实现 ViT 并完成分类任务；  
- 采用至少一种不均衡处理方法；  
- 采用两种轻量化方法（Dynamic ViT、AViT 或量化）；  
- 对比性能与复杂度；  
- 提交实验报告与源码。

---

## 3. 实验环境与工具

| 项目     | 说明                                                      |
| -------- | --------------------------------------------------------- |
| 开发框架 | PyTorch 2.3.0                                             |
| 硬件环境 | NVIDIA RTX 3060 GPU × 1                                   |
| 操作系统 | Windows 11                                                |
| 主要库   | numpy、torch、torchvision、torchsummary、matplotlib、timm |

---

## 4. 实验项目结构说明

项目采用模块化设计，整体目录结构如下：

```bash
D:.
│  .gitignore
│  best_vit_model.pth
│  best_vit_model_quantized.pth
│  config.json
│  directory_structure.txt
│  quantize_model.py
│  README.md
│  ViT.py
│  ViT_PVT.py
│  ViT_train.py
│  实验报告.md
│  模型参数量和FLOPs.py
│  绘图小工具.py
│  
├─CIFAR10_balanced
│  └─CIFAR10_balance
│              
├─CIFAR10_imbalanced
│  └─CIFAR10_unbalance
│              
├─training_plots
│      
└─__pycache__
```



---

## 5. 模型设计与实现

### .1 基础 ViT 模型构建

Vision Transformer (ViT) 的核心思想是将图像视为一维序列处理，从而利用 Transformer 架构进行全局特征建模。

**主要结构包括：**
1. **Patch Embedding 层**：  
   将输入图像分割为固定大小的 patch（如 16×16），并通过线性映射嵌入到高维特征空间中。  
   数学表达为：
   $$
   \mathbf{z}_0 = [x_1E; x_2E; \dots; x_N E] + E_{pos}
   $$
   
2. **Transformer Encoder 模块**：  
   每个编码层包含多头自注意力（Multi-Head Self-Attention, MHSA）和前馈网络（Feed Forward Network, FFN），并使用残差连接与 LayerNorm 保持稳定训练。
   $$
   \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
   $$
   
3. **分类头 (MLP Head)**：  
   使用 `[CLS]` token 的输出经过线性层进行类别预测。

---

### 4.2 不均衡问题解决方法

CIFAR10_imbalanced 训练集的类别分布不均衡，使得模型更倾向于预测样本数量较多的类别。为此，我们采用以下两种方法改善训练效果。

#### 方法一：过采样 

- **过采样 (Oversampling)**：  
  对少数类样本进行重复采样，使各类别样本数量趋于平衡。  
  实现上可使用 `WeightedRandomSampler`，依据类别样本数量的倒数设置采样概率：
  $$
  p_i = \frac{1 / n_{c_i}}{\sum_j 1 / n_{c_j}}
  $$
  
  优点是实现简单，能有效改善训练偏向；缺点是可能造成过拟合。

  

#### 方法二：类别加权

- **类别加权 (Class Weighting)**：  
  在交叉熵损失中对各类别分配不同权重，使模型在训练中对少数类样本施加更大的损失。  
  $$
  \mathcal{L} = - \sum_{i=1}^C w_i \, y_i \log(p_i)
  $$
  
  优点是易于实现，能有效缓解类别不平衡带来的梯度偏移。

  

---

### 4.3 模型轻量化设计

在保持分类性能基本不变的前提下，减少模型的参数量和计算量（FLOPs）。  
本实验采用两种轻量化方法：**Dynamic ViT** 与 **AViT + 量化**。

#### 方法一：Dynamic ViT

Dynamic ViT 的核心思想是让模型根据输入样本的复杂度**动态调整计算量**。  
具体而言，通过学习一个 gating 模块，预测每个 token 在后续层是否继续参与计算。

**原理：**

1. 为每个 token 计算重要性得分 \(g_i \in [0,1]\)；
2. 当 \(g_i < \tau\)时，该 token 被丢弃；
3. Transformer 后续层仅计算剩余 token，从而节省计算量。

这样，模型在处理“简单”图像时可以跳过部分计算，显著降低推理时延。

**优势：**
- 不依赖硬件特性；
- 可在保持精度的同时减少约 30–40% FLOPs。

#### 方法二：AViT + 量化

**1️⃣ AViT（Adaptive Vision Transformer）**

AViT 通过引入可学习的注意力稀疏控制模块，实现“自适应计算预算（Adaptive Compute Budget）”。

- 不同输入图像根据自身特征复杂度动态分配注意力计算资源；
- 模型在训练过程中自动学习如何平衡“精度”与“速度”；
- 类似于在动态 ViT 的基础上加入更精细的 token 选择机制。

**2️⃣ 模型量化 (Quantization)**

量化通过降低模型权重与激活值的数值精度（如从 32-bit 浮点转为 8-bit 整数），减少存储与计算成本。

量化主要包括：
- **权重量化**：  
  \[
  w_q = \text{round}\left( \frac{w}{s} \right) \times s
  \]
  其中 \(s\) 为缩放因子。
- **激活量化**：对中间特征进行相似的离散化。

**优势：**
- 减少约 70% 存储需求；
- 提高推理速度，尤其在低功耗设备上；
- 对精度影响较小。

---

### 4.4 模型设计总结

| 模块     | 方法                  | 核心思想                 | 目标           |
| -------- | --------------------- | ------------------------ | -------------- |
| 数据平衡 | 过采样     | 平衡训练样本数量         | 减少类别偏差   |
| 损失函数 | 类别加权 | 增强少数类影响           | 改善模型鲁棒性 |
| 轻量化①  | Dynamic ViT           | 动态丢弃无用 token       | 降低计算量     |
| 轻量化②  | AViT + 量化           | 自适应注意力与低比特精度 | 提升推理速度   |

---

- 

  

---

## 6. 实验过程与结果

### 6.1 实验设置

| 参数          | 值                        |
| ------------- | ------------------------- |
| Batch Size    | 128                       |
| Optimizer     | AdamW                     |
| Learning Rate | 1e-4                      |
| Epochs        | 350                       |
| Scheduler     | Cosine Annealing          |
| Loss          | CrossEntropy / Focal Loss |

### 6.2 实验结果展示

| 模型        | 准确率(%) | 参数量(M) | FLOPs(G) |
| ----------- | --------- | --------- | -------- |
| 原始 ViT    | 75.60     | 10.72     | 0.18G    |
| AViT + 量化 | 72.34     | 8.14      | 0.14G    |

![cdc59438927cae0f8916776f4a3ca5fc](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\cdc59438927cae0f8916776f4a3ca5fc.png)



**训练与验证准确率曲线如下（示意）：**

**ViT模型**

![3b21eccc049d85894db70dd98e0db9d8](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\3b21eccc049d85894db70dd98e0db9d8.png)



**AViT模型**

![4adf3c748ceaf087eeba50f8fa75558d](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\4adf3c748ceaf087eeba50f8fa75558d.png)



**FLOPS指标**

**ViT模型**

![7fd8c2768a001935b88281f8123eda18](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\7fd8c2768a001935b88281f8123eda18.png)

**AViT模型**

![576e0504a8c3f47eb7af2ce44b154e53](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\576e0504a8c3f47eb7af2ce44b154e53.png)



**量化**

![cca795383bc0fa9511ec7a2d719fd7ef](D:\Zhewe\Documents\Tencent Files\3228823091\nt_qq\nt_data\Pic\2025-10\Ori\cca795383bc0fa9511ec7a2d719fd7ef.png)



---

## 7. 实验难点与特点分析

### 7.1 实验难点
1. **模型结构复杂**：ViT 含多层 Transformer，需要仔细调整层数、维度与注意力头数。  
2. **数据不均衡带来的偏置问题**：若不处理，模型会严重倾向于预测多数类。  
3. **轻量化方案平衡困难**：减小参数量往往导致性能下降，需要实验调参权衡。

### 7.2 实验特点
- 综合考虑分类性能、模型复杂度与推理速度；
- 采用模块化结构，便于扩展 Dynamic ViT 与量化实验；
- 提供通用的不均衡数据处理框架，可复用于其他任务。

---

## 8. 结果分析与讨论
- **不均衡处理效果**：Focal Loss 显著提升了少数类的召回率；  
- **轻量化效果**：Dynamic ViT 和量化均能降低 FLOPs 与推理时延；  
- **性能对比**：轻量化模型在保持精度的同时减少约 40% 参数量。

---

## 9. 结论与展望
本实验成功实现了 ViT 在 CIFAR-10 数据集上的分类任务，探索了不均衡处理与轻量化的有效方法。未来可在以下方向继续改进：
- 引入蒸馏（Distillation）提升轻量化模型性能；
- 尝试 Token Pruning 或 Sparse Attention 以进一步减少计算量。

---

## 10. 组员分工与贡献比例

| 组员   | 学号       | 主要贡献             | 占比 |
| ------ | ---------- | -------------------- | ---- |
| 谢霖舒 | U202213810 | ViT 模型实现与调参   | 40%  |
| 徐文涛 | U202213811 | 不均衡处理与结果分析 | 30%  |
| 胡哲玮 | U202213821 | 轻量化设计与报告撰写 | 30%  |

---

## 11. 参考文献
1. Dosovitskiy et al., *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale*, ICLR 2021.  
2. Touvron et al., *Training data-efficient image transformers & distillation through attention*, ICML 2021.  
3. Han et al., *Dynamic ViT: Efficient Vision Transformers with Adaptive Token Sampling*, NeurIPS 2021.  
4. Yin et al., *AViT: Adaptive Vision Transformer for Efficient Image Recognition*, CVPR 2022.  